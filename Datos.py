import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score
import gzip
import pickle
import xgboost as xgb
from joblib import load
from tensorflow.keras.models import load_model
import tensorflow as tf



# Mostrar la imagen solo en la p√°gina de inicio
st.title("An√°lisis de Detecci√≥n de Ocupaci√≥n")
st.write("Grupo: Yulisa Ortiz Giraldo y Juan Pablo Nore√±a Londo√±o")
if "image_displayed" not in st.session_state:
    st.image("image1.jpg", use_container_width=True)
    st.session_state["image_displayed"] = True  # Marcar que la imagen ya se mostr√≥

# Crear una tabla de contenido en la barra lateral
seccion = st.sidebar.radio("Tabla de Contenidos", 
                           ["Vista previa de los datos", 
                            "Informaci√≥n del dataset", 
                            "An√°lisis Descriptivo", 
                            "Mapa de calor de correlaciones", 
                            "Distribuci√≥n de la variable objetivo", 
                            "Boxplots", 
                            "Conclusi√≥n: Selecci√≥n del Mejor Modelo",  # Nueva ubicaci√≥n
                            "Modelo Random Forest",  # Nueva secci√≥n
                            "Modelo de redes neuronales"])
# Cargar datos
@st.cache_data
def load_data():
    df_train = pd.read_csv("https://raw.githubusercontent.com/JuanPablo9999/Mineria_de_datos_streamlit/main/datatrain.csv")
    df_test = pd.read_csv("https://raw.githubusercontent.com/JuanPablo9999/Mineria_de_datos_streamlit/main/datatest.csv")
    return df_train, df_test

df_train, df_test = load_data()

# Preprocesamiento de datos
for df in [df_train, df_test]:
    df.drop(columns=["id", "date"], inplace=True, errors='ignore')

def preprocess_data(train_df, test_df):
    X_train = train_df.drop(columns=["Occupancy"], errors='ignore')
    y_train = train_df["Occupancy"]
    X_test = test_df.drop(columns=["Occupancy"], errors='ignore')
    y_test = test_df["Occupancy"]
    
    scaler = MinMaxScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    return X_train_scaled, X_test_scaled, y_train, y_test, scaler

X_train, X_test, y_train, y_test, scaler = preprocess_data(df_train, df_test)


# Mostrar contenido basado en la selecci√≥n
if seccion == "Vista previa de los datos":
    st.subheader("Vista previa de los datos")
    st.write(df.head())

elif seccion == "Informaci√≥n del dataset":
    st.subheader("Informaci√≥n del dataset")
    st.write(df.info())
    st.write("La base de datos seleccionada para el desarrollo de la aplicaci√≥n corresponde a un estudio dise√±ado para optimizar actividades de clasificaci√≥n binaria para determinar s√≠ una habitaci√≥n est√° ocupada o no. Dentro de sus caracter√≠sticas, se recopilan mediciones ambientales tales como la temperatura, la humedad del ambiente, la luz o nivel de luminosidad, y niveles de CO2, donde, con base a estas se determina s√≠ la habitaci√≥n est√° ocupada. La informaci√≥n de ocupaci√≥n se obtuvo mediante la obtenci√≥n de im√°genes capturadas por minuto, garantizando etiquetas precisas para la clasificaci√≥n. Este conjunto de datos resulta muy importante y √∫til para la investigaci√≥n basada en la detecci√≥n ambiental y el dise√±o de sistemas de edificios inteligentes seg√∫n sea el inter√©s del usuario.")
    st.write("La base cuenta con un total de 17.895 datos con un total de 8 variables, sin embargo, se utilizar√° una cantidad reducida de variables debido a que aquellas como ‚ÄúID‚Äù y ‚ÄúFecha‚Äù no aportan informaci√≥n relevante para la aplicaci√≥n de los temas anteriormente tratados.")
    st.write("El conjunto de datos fue obtenido del repositorio p√∫blico Kaggle, ampliamente utilizado en investigaciones relacionadas con sistemas inteligentes y monitoreo ambiental. La fuente original corresponde al trabajo disponible en el siguiente enlace: https://www.kaggle.com/datasets/pooriamst/occupancy-detection.")

elif seccion == "An√°lisis Descriptivo":
    st.subheader("Resumen de los datos")
    st.write(df.describe())
    st.subheader("Histograma de Temperature")
    # Temperatura
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(x=df["Temperature"], bins=30, color='blue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('Temperature')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Histograma de Temperature')
    st.pyplot(fig)
    st.write("Del histograma anterior, se denota que la mayor√≠a de im√°genes tomadas de la habitaci√≥n captaron una temperatura de entre 20¬∞C y 21¬∞C, siendo una temperatura ambiente la que m√°s predomina en el conjunto de datos. Adem√°s, se observa que la temperatura m√≠nima registrada es de 19¬∞C y la m√°xima es un poco superior a 24¬∞C. Por tanto, en la habitaci√≥n no hay presencia de temperaturas que se consideren bajas o altas.")
    #  Humidity
    st.subheader("Histograma de Humidity")
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(x=df["Humidity"], bins=30, color='blue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('Humidity')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Histograma de Humidity')
    st.pyplot(fig)
    st.write("De la variable ‚ÄúHumidity‚Äù, se observa que la humedad se encuentra entre aproximadamente un 16% y un 40%. Para su interpretaci√≥n en este caso, se debe conocer cu√°les son los valores de humedad normales en una habitaci√≥n, para ello, la empresa Philips (sin fecha) en su publicaci√≥n ‚Äú¬øC√≥mo medir la humedad recomendada en casa?‚Äù afirma que la humedad ideal debe encontrarse entre 30% y 60% para la conservaci√≥n de los materiales de las paredes y el piso; por otra parte, en el blog Siber. (n.d.) mencionan que el ser humano puede estar en espacios con una humedad de 20% a 75%. Teniendo en cuenta lo anterior, se puede afirmar que la humedad en la mayor√≠a de los datos es adecuada para las personas, para los casos cuyo valor de humedad es menor a 20% no resulta ideal pero no deber√≠a ser un inconveniente significativo.")
    # HumidityRatio
    st.subheader("Histograma de HumidityRatio")
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(x=df["HumidityRatio"], bins=30, color='blue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('HumidityRatio')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Histograma de HumidityRatio')
    st.pyplot(fig)
    st.write("Este histograma corresponde a la cantidad derivada de la temperatura y la humedad relativa dada en kilogramo de vapor de agua por kilogramo de aire, los valores se encuentran entre 0.002 kg vapor de agua/kg de aire hasta 0.0065 kg vapor de agua/ kg de aire aproximadamente. Seg√∫n la explicaci√≥n de la variable anterior, los resultados de la relaci√≥n se encuentran en un rango adecuado.")
    # Light
    st.subheader("Histograma de Light")
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(x=df["Light"], bins=30, color='blue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('Light')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Histograma de Light')
    st.pyplot(fig)
    st.write("De la variable Light, se observa que en la gran mayor√≠a de los datos no hubo presencia de luz, no obstante, se denota el incremento en los valores cercanos a 500lux, esto indica que en estos casos s√≠ se hizo uso de la luz el√©ctrica en la habitaci√≥n debido al flujo luminoso provocado por el bombillo. Este podr√≠a ser un factor importante en la determinaci√≥n de s√≠ la habitaci√≥n est√° ocupada o no, pero esto se confirmar√° m√°s adelante en los resultados.")
    # CO2
    st.subheader("Histograma de CO2")
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(x=df["CO2"], bins=30, color='blue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('CO2')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Histograma de CO2')
    st.pyplot(fig)
    st.write("Para la variable de CO2, se observa que los niveles de CO2 dados en ppm (part√≠culas por mill√≥n) de aproximadamente 400 a 700pm son los m√°s presentes en el conjunto de datos. Se registran m√°s casos donde los niveles de CO2 son mucho mayores a los recurrentes, llegando hasta los 2000ppm. Para comprender la tolerancia de una persona hacia el CO2, la empresa Enectiva (2017) en su publicaci√≥n ‚ÄúEfectos de la concentraci√≥n de CO‚ÇÇ para la salud humana‚Äù expone que las habitaciones deben tener niveles de CO2 m√°ximo recomendado en 1200-1500ppm, a partir de este valor pueden presentarse efectos secundarios sobre las personas, como la fatiga y la p√©rdida de concentraci√≥n; a niveles mayores a los presentes en el histograma puede provocar aumento del ritmo card√≠aco, dificultades respiratorias, n√°useas, e inclusive la p√©rdida de la consciencia. Los niveles de CO2 pueden ser un indicativo clave para determinar s√≠ la habitaci√≥n est√° ocupada o no debido a la naturaleza del ser humano de expulsar di√≥xido de carbono ‚ÄúCO2‚Äù en su exhalaci√≥n, aunque debe tenerse en cuenta que un nivel elevado de CO2 puede deberse a razones diferentes del proceso de respiraci√≥n de la persona.")
    
elif seccion == "Distribuci√≥n de la variable objetivo":
    st.subheader("Distribuci√≥n de la variable objetivo")
    fig, ax = plt.subplots()
    sns.countplot(x=df["Occupancy"], ax=ax)
    st.pyplot(fig)
    st.write("De la variable respuesta ‚ÄúOccupancy‚Äù, se obtiene que en su mayor√≠a de casos se tiene como resultado que la habitaci√≥n no se encuentra ocupada, denotada con el valor de cero y por el valor 1 en el caso contrario. Se obtuvo que en el 78.9% de los casos la habitaci√≥n est√° vac√≠a, y en el 21.1% se encuentra ocupada.")

elif seccion == "Mapa de calor de correlaciones":
    st.subheader("Mapa de calor de correlaciones")
    st.write("Se plantea la matriz de correlaci√≥n de las variables mencionadas para verificar qu√© tan relacionadas se encuentran con la variable respuesta de ‚ÄúOccupancy‚Äù y as√≠ observar cu√°les tendr√≠an mayor incidencia en la toma de decisi√≥n:")
    fig, ax = plt.subplots(figsize=(10, 5))
    sns.heatmap(df.corr(), vmin=-1, vmax=1, cmap="coolwarm", annot=True, ax=ax)
    st.pyplot(fig)
    st.write("Seg√∫n la matriz, la variable que m√°s se correlaciona con la variable respuesta es la luz (‚ÄúLight‚Äù), pues es una determinante importante en la ocupaci√≥n de una habitaci√≥n; seguido de √©sta, se denotan las variables de temperatura y CO2, cuyas caracter√≠sticas se encuentran estrechamente relacionadas con la presencia de personas en un espacio. Por √∫ltimo, debe mencionarse que las variables relacionadas con la humedad presentan una muy baja correlaci√≥n con la ocupaci√≥n de una habitaci√≥n, esto debe tenerse en cuenta en la formulaci√≥n del modelo para la aplicaci√≥n y considerar s√≠ se eliminan estas variables dependiendo de los resultados que se obtengan.")

elif seccion == "Boxplots":
    st.subheader("Conjunto de boxplots")
    st.image("Boxplots.jpeg", use_container_width=True)
    st.write("""
    ### An√°lisis de Variables

    #### CO2 (Di√≥xido de carbono):
    - **Habitaci√≥n vac√≠a (rojo):** Niveles considerablemente m√°s bajos, con una mediana en torno a 500ppm.
    - **Habitaci√≥n ocupada (verde):** Niveles mucho m√°s altos, con una mediana cerca de 1000ppm.
    - El nivel de CO2 aumenta notablemente con la ocupaci√≥n, posiblemente debido a la respiraci√≥n de las personas.

    #### Humidity (Humedad):
    - **Habitaci√≥n vac√≠a (rojo):** Mediana ligeramente por encima de 25, con dispersi√≥n moderada.
    - **Habitaci√≥n ocupada (verde):** Mediana cerca de 30, con valores m√°s altos.
    - La ocupaci√≥n no parece variar mucho la humedad, en l√≠nea con la matriz de correlaciones.

    #### HumidityRatio (Proporci√≥n de humedad):
    - **Habitaci√≥n vac√≠a (rojo):** Valores concentrados alrededor de 0.0035.
    - **Habitaci√≥n ocupada (verde):** Valores ligeramente m√°s altos, alrededor de 0.004.
    - Aunque las diferencias no son grandes, la ocupaci√≥n est√° asociada con un peque√±o incremento en la proporci√≥n de humedad.

    #### Light (Luz):
    - **Habitaci√≥n vac√≠a (rojo):** Gran dispersi√≥n, con valores extremos muy altos.
    - **Habitaci√≥n ocupada (verde):** Valores m√°s bajos y concentrados.
    - La ocupaci√≥n 0 (habitaci√≥n vac√≠a) est√° asociada con niveles de luz m√°s altos y variables, posiblemente por la ausencia de personas que reduzcan el uso de iluminaci√≥n artificial.

    #### Temperature (Temperatura):
    - **Habitaci√≥n vac√≠a (rojo):** Mediana cerca de 20¬∞C, con dispersi√≥n moderada.
    - **Habitaci√≥n ocupada (verde):** Mediana ligeramente m√°s alta, alrededor de 22¬∞C.
    - La temperatura es m√°s alta con ocupaci√≥n, posiblemente por el calor generado por las personas o el uso de calefacci√≥n.

     #### Conclusi√≥n:
    La ocupaci√≥n tiene un impacto claro en **CO2, Light (luz) y Temperature (temperatura)**, aumentando sus valores en comparaci√≥n con la falta de ocupaci√≥n. En particular, la luz tiende a ser m√°s alta y variable cuando hay ocupaci√≥n. Otras variables como la humedad presentan cambios menores, pero no son significativos.
    """)

# Nueva secci√≥n: Conclusi√≥n sobre la selecci√≥n del mejor modelo
elif seccion == "Conclusi√≥n: Selecci√≥n del Mejor Modelo":
    st.subheader("Conclusi√≥n: Selecci√≥n del Mejor Modelo (Random Forest)")
    st.markdown("""
    Despu√©s de evaluar varios modelos de machine learning para la tarea de predecir la ocupaci√≥n de habitaciones, se determin√≥ que el **Random Forest Classifier** es el modelo m√°s adecuado para este problema. A continuaci√≥n, se detallan las razones por las que se seleccion√≥ este modelo y por qu√© los otros no fueron la mejor opci√≥n:

    #### Razones para elegir Random Forest:
    1. **Alto Rendimiento en Precisi√≥n y F1-Score**:
       - Random Forest demostr√≥ un excelente rendimiento en t√©rminos de precisi√≥n y F1-Score, logrando un buen equilibrio entre la clasificaci√≥n de habitaciones ocupadas y desocupadas.

    2. **Manejo de Desequilibrio de Clases**:
       - Random Forest maneja bien el desequilibrio de clases gracias a su estructura de ensamble de m√∫ltiples √°rboles de decisi√≥n, mejorando la generalizaci√≥n.

    3. **Interpretabilidad de las Caracter√≠sticas**:
       - Random Forest proporciona una interpretaci√≥n clara de la importancia de las caracter√≠sticas, permitiendo identificar variables clave como el nivel de CO2, la luz y la humedad en la predicci√≥n de ocupaci√≥n.

    4. **Robustez ante Overfitting**:
       - Debido a su naturaleza basada en ensambles de m√∫ltiples √°rboles, Random Forest es menos propenso al sobreajuste en comparaci√≥n con modelos individuales como Decision Tree.

    5. **Eficiencia y Escalabilidad**:
       - Aunque puede ser computacionalmente m√°s costoso que algunos modelos m√°s simples, su rendimiento general lo hace una excelente opci√≥n para conjuntos de datos medianos y grandes.

    #### Razones por las que otros modelos no fueron seleccionados:
    - **XGBoost**: Aunque XGBoost es un modelo muy potente, en este caso Random Forest logr√≥ un rendimiento similar con menor complejidad y menor necesidad de ajuste de hiperpar√°metros.
    
    - **Decision Tree**: Es propenso al overfitting y no generaliza tan bien como Random Forest, ya que se basa en un solo √°rbol en lugar de un ensamble.
    
    - **K-Nearest Neighbors (KNN)**: Requiere mucho c√°lculo a medida que aumenta el tama√±o de los datos y no maneja bien el desequilibrio de clases.
    
    - **Red Neuronal**: Aunque las redes neuronales pueden ser muy poderosas, en este caso el modelo Random Forest alcanz√≥ una mejor interpretabilidad y robustez sin necesidad de ajustes complejos.

    ### Conclusi√≥n Final:
    El **Random Forest Classifier** fue seleccionado como el mejor modelo debido a su alto rendimiento, capacidad para manejar el desequilibrio de clases, interpretabilidad de las caracter√≠sticas y robustez ante el overfitting. Estos factores lo convierten en la opci√≥n m√°s adecuada para la tarea de predecir la ocupaci√≥n de habitaciones, superando a otros modelos como XGBoost, Decision Tree, KNN y la red neuronal en este contexto espec√≠fico.
    """)

# ==============================
# SECCI√ìN: RANDOM FOREST
# ==============================
if seccion == "Modelo Random Forest":
    st.subheader("Modelo Random Forest: Predicci√≥n de Ocupaci√≥n")
    st.markdown("""
    En esta secci√≥n, exploraremos el modelo **Random Forest** para predecir la ocupaci√≥n de habitaciones bas√°ndonos en las siguientes variables:
    - **Temperature**: Temperatura en la habitaci√≥n.
    - **Humidity**: Humedad en la habitaci√≥n.
    - **Light**: Nivel de luz en la habitaci√≥n.
    - **CO2**: Nivel de di√≥xido de carbono en la habitaci√≥n.
    - **HumidityRatio**: Relaci√≥n de humedad en la habitaci√≥n.
    - **Occupancy**: Variable objetivo que indica si la habitaci√≥n est√° ocupada (1) o no (0).
     """)

    # Cargar el modelo
    def load_model():
        try:
            with gzip.open('random_forest_model.pkl.gz', 'rb') as f:
                model = pickle.load(f)
            return model
        except Exception as e:
            st.error(f"Error al cargar el modelo: {e}")
            return None

    # Verificar si el modelo est√° cargado en la sesi√≥n
    if "model" not in st.session_state:
        st.session_state.model = load_model()

    if st.session_state.model is not None:
        st.success("Modelo cargado correctamente.")
        model = st.session_state.model

        # **Solo aparece en la secci√≥n Random Forest**
        st.markdown("### Hacer una predicci√≥n")
        st.write("Introduce valores para hacer una predicci√≥n:")
        inputs = {}

        # Diccionario con valores m√≠nimos y m√°ximos de cada variable
        min_max_dict = {
            'Temperature': (19.0, 25.0),
            'Humidity': (20.0, 60.0),
            'Light': (0.0, 1500.0),
            'CO2': (400.0, 1200.0),
            'HumidityRatio': (0.003, 0.007)
        }

        columnas_modelo = list(min_max_dict.keys())

        for col in columnas_modelo:
            min_val, max_val = min_max_dict[col]
            min_val, max_val = float(min_val), float(max_val)
            inputs[col] = st.number_input(
                f"{col} ({min_val} - {max_val})", 
                min_value=min_val, 
                max_value=max_val, 
                value=(min_val + max_val) / 2
            )

        if st.button("Predecir"):
            input_df = pd.DataFrame([inputs])
            prediccion = model.predict(input_df)
            ocupacion = "Ocupada" if prediccion[0] == 1 else "No Ocupada"
            st.success(f"La predicci√≥n de ocupaci√≥n es: {ocupacion}")

            # Importancia de las variables
            st.markdown("### Importancia de las variables")
            importancia = model.feature_importances_
            imp_df = pd.DataFrame({'Variable': columnas_modelo, 'Importancia': importancia})
            imp_df = imp_df.sort_values(by='Importancia', ascending=False)

            plt.figure(figsize=(8, 5))
            sns.barplot(x='Importancia', y='Variable', data=imp_df, palette='viridis')
            st.pyplot(plt)

    else:
        st.error("No se pudo cargar el modelo. Verifica el archivo.")

    st.sidebar.info("Esta aplicaci√≥n predice la ocupaci√≥n de una habitaci√≥n usando un modelo Random Forest.")

# ==============================
# SECCI√ìN: REDES NEURONALES
# ==============================
# Cargar el modelo y el scaler
model_path = "best_model.h5"
scaler_path = "scaler.pkl"

@st.cache_resource
def load_model():
    model_path = "/mnt/data/best_model.h5"
    return tf.keras.models.load_model(model_path)

model = load_model()

@st.cache_resource
def load_scaler():
    return joblib.load(scaler_path)

model = load_model()
scaler = load_scaler()

# Definir hiperpar√°metros utilizados en el modelo
hyperparams = {
    'depth': 1,
    'epochs': 5,
    'num_units': 176,
    'optimizer': 'rmsprop',
    'activation': 'relu',
    'batch_size': 24,
    'learning_rate': 0.065
}

# Interfaz de Streamlit
st.title("üìä An√°lisis de Redes Neuronales")
st.write("Este m√≥dulo presenta el an√°lisis del modelo de redes neuronales entrenado para predecir la ocupaci√≥n de un espacio en funci√≥n de variables ambientales.")

st.subheader("üîß Hiperpar√°metros Utilizados")
st.json(hyperparams)

# Cargar dataset de prueba
st.subheader("üìä Evaluaci√≥n del Modelo")
data = pd.read_csv("datatrain.csv")
features = ['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio']
target = 'Occupancy'

X_test = scaler.transform(data[features])
y_test = data[target]
y_pred = model.predict(X_test)
y_pred_class = (y_pred > 0.5).astype(int)

# Matriz de confusi√≥n
st.subheader("üìå Matriz de Confusi√≥n")
cm = confusion_matrix(y_test, y_pred_class)
fig, ax = plt.subplots()
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Ocupado', 'Ocupado'], yticklabels=['No Ocupado', 'Ocupado'])
plt.xlabel("Predicci√≥n")
plt.ylabel("Real")
st.pyplot(fig)

# Reporte de clasificaci√≥n
st.subheader("üìÑ Reporte de Clasificaci√≥n")
st.text(classification_report(y_test, y_pred_class))

# Curvas de entrenamiento (si est√°n disponibles)
st.subheader("üìà Curvas de Entrenamiento")
if "history.pkl" in scaler_path:
    history = joblib.load("history.pkl")
    fig, ax = plt.subplots(1, 2, figsize=(12, 5))
    ax[0].plot(history['loss'], label='P√©rdida Entrenamiento')
    ax[0].plot(history['val_loss'], label='P√©rdida Validaci√≥n')
    ax[0].legend()
    ax[0].set_title("Evoluci√≥n de la P√©rdida")
    
    ax[1].plot(history['accuracy'], label='Precisi√≥n Entrenamiento')
    ax[1].plot(history['val_accuracy'], label='Precisi√≥n Validaci√≥n')
    ax[1].legend()
    ax[1].set_title("Evoluci√≥n de la Precisi√≥n")
    
    st.pyplot(fig)
else:
    st.warning("No se encontraron datos de historial de entrenamiento.")

# Secci√≥n de predicciones interactivas
st.subheader("üîÆ Predicciones Interactivas")

def user_input():
    temp = st.number_input("Temperatura (¬∞C)", min_value=19.0, max_value=25.0, value=22.0)
    hum = st.number_input("Humedad (%)", min_value=20.0, max_value=60.0, value=40.0)
    light = st.number_input("Luz (lux)", min_value=0.0, max_value=1500.0, value=750.0)
    co2 = st.number_input("CO2 (ppm)", min_value=400.0, max_value=1200.0, value=800.0)
    hum_ratio = st.number_input("Humedad Ratio", min_value=0.003, max_value=0.007, value=0.005)
    return np.array([[temp, hum, light, co2, hum_ratio]])

input_data = user_input()
scaled_input = scaler.transform(input_data)
prediction = model.predict(scaled_input)
occupancy_status = "Ocupado" if prediction > 0.5 else "No Ocupado"

st.write(f"**Predicci√≥n: {occupancy_status} (Probabilidad: {prediction[0][0]:.2f})**")
