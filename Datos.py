import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score
import gzip
import pickle
import xgboost as xgb
from joblib import load
from tensorflow.keras.models import load_model
import tensorflow as tf



# Mostrar la imagen solo en la pÃ¡gina de inicio
st.title("AnÃ¡lisis de DetecciÃ³n de OcupaciÃ³n")
st.write("Grupo: Yulisa Ortiz Giraldo y Juan Pablo NoreÃ±a LondoÃ±o")
if "image_displayed" not in st.session_state:
    st.image("image1.jpg", use_container_width=True)
    st.session_state["image_displayed"] = True  # Marcar que la imagen ya se mostrÃ³

# Crear una tabla de contenido en la barra lateral
seccion = st.sidebar.radio("Tabla de Contenidos", 
                           ["Vista previa de los datos", 
                            "InformaciÃ³n del dataset", 
                            "AnÃ¡lisis Descriptivo", 
                            "Mapa de calor de correlaciones", 
                            "DistribuciÃ³n de la variable objetivo", 
                            "Boxplots", 
                            "ConclusiÃ³n: SelecciÃ³n del Mejor Modelo",  # Nueva ubicaciÃ³n
                            "Modelo Random Forest",  # Nueva secciÃ³n
                            "Modelo de redes neuronales"])
# Cargar datos
@st.cache_data
def load_data():
    df_train = pd.read_csv("https://raw.githubusercontent.com/JuanPablo9999/Mineria_de_datos_streamlit/main/datatrain.csv")
    df_test = pd.read_csv("https://raw.githubusercontent.com/JuanPablo9999/Mineria_de_datos_streamlit/main/datatest.csv")
    return df_train, df_test

df_train, df_test = load_data()

# Preprocesamiento de datos
for df in [df_train, df_test]:
    df.drop(columns=["id", "date"], inplace=True, errors='ignore')

def preprocess_data(train_df, test_df):
    X_train = train_df.drop(columns=["Occupancy"], errors='ignore')
    y_train = train_df["Occupancy"]
    X_test = test_df.drop(columns=["Occupancy"], errors='ignore')
    y_test = test_df["Occupancy"]
    
    scaler = MinMaxScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    return X_train_scaled, X_test_scaled, y_train, y_test, scaler

X_train, X_test, y_train, y_test, scaler = preprocess_data(df_train, df_test)


# Mostrar contenido basado en la selecciÃ³n
if seccion == "Vista previa de los datos":
    st.subheader("Vista previa de los datos")
    st.write(df.head())

elif seccion == "InformaciÃ³n del dataset":
    st.subheader("InformaciÃ³n del dataset")
    st.write(df.info())
    st.write("La base de datos seleccionada para el desarrollo de la aplicaciÃ³n corresponde a un estudio diseÃ±ado para optimizar actividades de clasificaciÃ³n binaria para determinar sÃ­ una habitaciÃ³n estÃ¡ ocupada o no. Dentro de sus caracterÃ­sticas, se recopilan mediciones ambientales tales como la temperatura, la humedad del ambiente, la luz o nivel de luminosidad, y niveles de CO2, donde, con base a estas se determina sÃ­ la habitaciÃ³n estÃ¡ ocupada. La informaciÃ³n de ocupaciÃ³n se obtuvo mediante la obtenciÃ³n de imÃ¡genes capturadas por minuto, garantizando etiquetas precisas para la clasificaciÃ³n. Este conjunto de datos resulta muy importante y Ãºtil para la investigaciÃ³n basada en la detecciÃ³n ambiental y el diseÃ±o de sistemas de edificios inteligentes segÃºn sea el interÃ©s del usuario.")
    st.write("La base cuenta con un total de 17.895 datos con un total de 8 variables, sin embargo, se utilizarÃ¡ una cantidad reducida de variables debido a que aquellas como â€œIDâ€ y â€œFechaâ€ no aportan informaciÃ³n relevante para la aplicaciÃ³n de los temas anteriormente tratados.")
    st.write("El conjunto de datos fue obtenido del repositorio pÃºblico Kaggle, ampliamente utilizado en investigaciones relacionadas con sistemas inteligentes y monitoreo ambiental. La fuente original corresponde al trabajo disponible en el siguiente enlace: https://www.kaggle.com/datasets/pooriamst/occupancy-detection.")

elif seccion == "AnÃ¡lisis Descriptivo":
    st.subheader("Resumen de los datos")
    st.write(df.describe())
    st.subheader("Histograma de Temperature")
    # Temperatura
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(x=df["Temperature"], bins=30, color='blue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('Temperature')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Histograma de Temperature')
    st.pyplot(fig)
    st.write("Del histograma anterior, se denota que la mayorÃ­a de imÃ¡genes tomadas de la habitaciÃ³n captaron una temperatura de entre 20Â°C y 21Â°C, siendo una temperatura ambiente la que mÃ¡s predomina en el conjunto de datos. AdemÃ¡s, se observa que la temperatura mÃ­nima registrada es de 19Â°C y la mÃ¡xima es un poco superior a 24Â°C. Por tanto, en la habitaciÃ³n no hay presencia de temperaturas que se consideren bajas o altas.")
    #  Humidity
    st.subheader("Histograma de Humidity")
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(x=df["Humidity"], bins=30, color='blue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('Humidity')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Histograma de Humidity')
    st.pyplot(fig)
    st.write("De la variable â€œHumidityâ€, se observa que la humedad se encuentra entre aproximadamente un 16% y un 40%. Para su interpretaciÃ³n en este caso, se debe conocer cuÃ¡les son los valores de humedad normales en una habitaciÃ³n, para ello, la empresa Philips (sin fecha) en su publicaciÃ³n â€œÂ¿CÃ³mo medir la humedad recomendada en casa?â€ afirma que la humedad ideal debe encontrarse entre 30% y 60% para la conservaciÃ³n de los materiales de las paredes y el piso; por otra parte, en el blog Siber. (n.d.) mencionan que el ser humano puede estar en espacios con una humedad de 20% a 75%. Teniendo en cuenta lo anterior, se puede afirmar que la humedad en la mayorÃ­a de los datos es adecuada para las personas, para los casos cuyo valor de humedad es menor a 20% no resulta ideal pero no deberÃ­a ser un inconveniente significativo.")
    # HumidityRatio
    st.subheader("Histograma de HumidityRatio")
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(x=df["HumidityRatio"], bins=30, color='blue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('HumidityRatio')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Histograma de HumidityRatio')
    st.pyplot(fig)
    st.write("Este histograma corresponde a la cantidad derivada de la temperatura y la humedad relativa dada en kilogramo de vapor de agua por kilogramo de aire, los valores se encuentran entre 0.002 kg vapor de agua/kg de aire hasta 0.0065 kg vapor de agua/ kg de aire aproximadamente. SegÃºn la explicaciÃ³n de la variable anterior, los resultados de la relaciÃ³n se encuentran en un rango adecuado.")
    # Light
    st.subheader("Histograma de Light")
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(x=df["Light"], bins=30, color='blue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('Light')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Histograma de Light')
    st.pyplot(fig)
    st.write("De la variable Light, se observa que en la gran mayorÃ­a de los datos no hubo presencia de luz, no obstante, se denota el incremento en los valores cercanos a 500lux, esto indica que en estos casos sÃ­ se hizo uso de la luz elÃ©ctrica en la habitaciÃ³n debido al flujo luminoso provocado por el bombillo. Este podrÃ­a ser un factor importante en la determinaciÃ³n de sÃ­ la habitaciÃ³n estÃ¡ ocupada o no, pero esto se confirmarÃ¡ mÃ¡s adelante en los resultados.")
    # CO2
    st.subheader("Histograma de CO2")
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(x=df["CO2"], bins=30, color='blue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('CO2')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Histograma de CO2')
    st.pyplot(fig)
    st.write("Para la variable de CO2, se observa que los niveles de CO2 dados en ppm (partÃ­culas por millÃ³n) de aproximadamente 400 a 700pm son los mÃ¡s presentes en el conjunto de datos. Se registran mÃ¡s casos donde los niveles de CO2 son mucho mayores a los recurrentes, llegando hasta los 2000ppm. Para comprender la tolerancia de una persona hacia el CO2, la empresa Enectiva (2017) en su publicaciÃ³n â€œEfectos de la concentraciÃ³n de COâ‚‚ para la salud humanaâ€ expone que las habitaciones deben tener niveles de CO2 mÃ¡ximo recomendado en 1200-1500ppm, a partir de este valor pueden presentarse efectos secundarios sobre las personas, como la fatiga y la pÃ©rdida de concentraciÃ³n; a niveles mayores a los presentes en el histograma puede provocar aumento del ritmo cardÃ­aco, dificultades respiratorias, nÃ¡useas, e inclusive la pÃ©rdida de la consciencia. Los niveles de CO2 pueden ser un indicativo clave para determinar sÃ­ la habitaciÃ³n estÃ¡ ocupada o no debido a la naturaleza del ser humano de expulsar diÃ³xido de carbono â€œCO2â€ en su exhalaciÃ³n, aunque debe tenerse en cuenta que un nivel elevado de CO2 puede deberse a razones diferentes del proceso de respiraciÃ³n de la persona.")
    
elif seccion == "DistribuciÃ³n de la variable objetivo":
    st.subheader("DistribuciÃ³n de la variable objetivo")
    fig, ax = plt.subplots()
    sns.countplot(x=df["Occupancy"], ax=ax)
    st.pyplot(fig)
    st.write("De la variable respuesta â€œOccupancyâ€, se obtiene que en su mayorÃ­a de casos se tiene como resultado que la habitaciÃ³n no se encuentra ocupada, denotada con el valor de cero y por el valor 1 en el caso contrario. Se obtuvo que en el 78.9% de los casos la habitaciÃ³n estÃ¡ vacÃ­a, y en el 21.1% se encuentra ocupada.")

elif seccion == "Mapa de calor de correlaciones":
    st.subheader("Mapa de calor de correlaciones")
    st.write("Se plantea la matriz de correlaciÃ³n de las variables mencionadas para verificar quÃ© tan relacionadas se encuentran con la variable respuesta de â€œOccupancyâ€ y asÃ­ observar cuÃ¡les tendrÃ­an mayor incidencia en la toma de decisiÃ³n:")
    fig, ax = plt.subplots(figsize=(10, 5))
    sns.heatmap(df.corr(), vmin=-1, vmax=1, cmap="coolwarm", annot=True, ax=ax)
    st.pyplot(fig)
    st.write("SegÃºn la matriz, la variable que mÃ¡s se correlaciona con la variable respuesta es la luz (â€œLightâ€), pues es una determinante importante en la ocupaciÃ³n de una habitaciÃ³n; seguido de Ã©sta, se denotan las variables de temperatura y CO2, cuyas caracterÃ­sticas se encuentran estrechamente relacionadas con la presencia de personas en un espacio. Por Ãºltimo, debe mencionarse que las variables relacionadas con la humedad presentan una muy baja correlaciÃ³n con la ocupaciÃ³n de una habitaciÃ³n, esto debe tenerse en cuenta en la formulaciÃ³n del modelo para la aplicaciÃ³n y considerar sÃ­ se eliminan estas variables dependiendo de los resultados que se obtengan.")

elif seccion == "Boxplots":
    st.subheader("Conjunto de boxplots")
    st.image("Boxplots.jpeg", use_container_width=True)
    st.write("""
    ### AnÃ¡lisis de Variables

    #### CO2 (DiÃ³xido de carbono):
    - **HabitaciÃ³n vacÃ­a (rojo):** Niveles considerablemente mÃ¡s bajos, con una mediana en torno a 500ppm.
    - **HabitaciÃ³n ocupada (verde):** Niveles mucho mÃ¡s altos, con una mediana cerca de 1000ppm.
    - El nivel de CO2 aumenta notablemente con la ocupaciÃ³n, posiblemente debido a la respiraciÃ³n de las personas.

    #### Humidity (Humedad):
    - **HabitaciÃ³n vacÃ­a (rojo):** Mediana ligeramente por encima de 25, con dispersiÃ³n moderada.
    - **HabitaciÃ³n ocupada (verde):** Mediana cerca de 30, con valores mÃ¡s altos.
    - La ocupaciÃ³n no parece variar mucho la humedad, en lÃ­nea con la matriz de correlaciones.

    #### HumidityRatio (ProporciÃ³n de humedad):
    - **HabitaciÃ³n vacÃ­a (rojo):** Valores concentrados alrededor de 0.0035.
    - **HabitaciÃ³n ocupada (verde):** Valores ligeramente mÃ¡s altos, alrededor de 0.004.
    - Aunque las diferencias no son grandes, la ocupaciÃ³n estÃ¡ asociada con un pequeÃ±o incremento en la proporciÃ³n de humedad.

    #### Light (Luz):
    - **HabitaciÃ³n vacÃ­a (rojo):** Gran dispersiÃ³n, con valores extremos muy altos.
    - **HabitaciÃ³n ocupada (verde):** Valores mÃ¡s bajos y concentrados.
    - La ocupaciÃ³n 0 (habitaciÃ³n vacÃ­a) estÃ¡ asociada con niveles de luz mÃ¡s altos y variables, posiblemente por la ausencia de personas que reduzcan el uso de iluminaciÃ³n artificial.

    #### Temperature (Temperatura):
    - **HabitaciÃ³n vacÃ­a (rojo):** Mediana cerca de 20Â°C, con dispersiÃ³n moderada.
    - **HabitaciÃ³n ocupada (verde):** Mediana ligeramente mÃ¡s alta, alrededor de 22Â°C.
    - La temperatura es mÃ¡s alta con ocupaciÃ³n, posiblemente por el calor generado por las personas o el uso de calefacciÃ³n.

     #### ConclusiÃ³n:
    La ocupaciÃ³n tiene un impacto claro en **CO2, Light (luz) y Temperature (temperatura)**, aumentando sus valores en comparaciÃ³n con la falta de ocupaciÃ³n. En particular, la luz tiende a ser mÃ¡s alta y variable cuando hay ocupaciÃ³n. Otras variables como la humedad presentan cambios menores, pero no son significativos.
    """)

# Nueva secciÃ³n: ConclusiÃ³n sobre la selecciÃ³n del mejor modelo
elif seccion == "ConclusiÃ³n: SelecciÃ³n del Mejor Modelo":
    st.subheader("ConclusiÃ³n: SelecciÃ³n del Mejor Modelo (Random Forest)")
    st.markdown("""
    DespuÃ©s de evaluar varios modelos de machine learning para la tarea de predecir la ocupaciÃ³n de habitaciones, se determinÃ³ que el **Random Forest Classifier** es el modelo mÃ¡s adecuado para este problema. A continuaciÃ³n, se detallan las razones por las que se seleccionÃ³ este modelo y por quÃ© los otros no fueron la mejor opciÃ³n:

    #### Razones para elegir Random Forest:
    1. **Alto Rendimiento en PrecisiÃ³n y F1-Score**:
       - Random Forest demostrÃ³ un excelente rendimiento en tÃ©rminos de precisiÃ³n y F1-Score, logrando un buen equilibrio entre la clasificaciÃ³n de habitaciones ocupadas y desocupadas.

    2. **Manejo de Desequilibrio de Clases**:
       - Random Forest maneja bien el desequilibrio de clases gracias a su estructura de ensamble de mÃºltiples Ã¡rboles de decisiÃ³n, mejorando la generalizaciÃ³n.

    3. **Interpretabilidad de las CaracterÃ­sticas**:
       - Random Forest proporciona una interpretaciÃ³n clara de la importancia de las caracterÃ­sticas, permitiendo identificar variables clave como el nivel de CO2, la luz y la humedad en la predicciÃ³n de ocupaciÃ³n.

    4. **Robustez ante Overfitting**:
       - Debido a su naturaleza basada en ensambles de mÃºltiples Ã¡rboles, Random Forest es menos propenso al sobreajuste en comparaciÃ³n con modelos individuales como Decision Tree.

    5. **Eficiencia y Escalabilidad**:
       - Aunque puede ser computacionalmente mÃ¡s costoso que algunos modelos mÃ¡s simples, su rendimiento general lo hace una excelente opciÃ³n para conjuntos de datos medianos y grandes.

    #### Razones por las que otros modelos no fueron seleccionados:
    - **XGBoost**: Aunque XGBoost es un modelo muy potente, en este caso Random Forest logrÃ³ un rendimiento similar con menor complejidad y menor necesidad de ajuste de hiperparÃ¡metros.
    
    - **Decision Tree**: Es propenso al overfitting y no generaliza tan bien como Random Forest, ya que se basa en un solo Ã¡rbol en lugar de un ensamble.
    
    - **K-Nearest Neighbors (KNN)**: Requiere mucho cÃ¡lculo a medida que aumenta el tamaÃ±o de los datos y no maneja bien el desequilibrio de clases.
    
    - **Red Neuronal**: Aunque las redes neuronales pueden ser muy poderosas, en este caso el modelo Random Forest alcanzÃ³ una mejor interpretabilidad y robustez sin necesidad de ajustes complejos.

    ### ConclusiÃ³n Final:
    El **Random Forest Classifier** fue seleccionado como el mejor modelo debido a su alto rendimiento, capacidad para manejar el desequilibrio de clases, interpretabilidad de las caracterÃ­sticas y robustez ante el overfitting. Estos factores lo convierten en la opciÃ³n mÃ¡s adecuada para la tarea de predecir la ocupaciÃ³n de habitaciones, superando a otros modelos como XGBoost, Decision Tree, KNN y la red neuronal en este contexto especÃ­fico.
    """)

# ==============================
# SECCIÃ“N: RANDOM FOREST
# ==============================
if seccion == "Modelo Random Forest":
    st.subheader("Modelo Random Forest: PredicciÃ³n de OcupaciÃ³n")
    st.markdown("""
    En esta secciÃ³n, exploraremos el modelo **Random Forest** para predecir la ocupaciÃ³n de habitaciones basÃ¡ndonos en las siguientes variables:
    - **Temperature**: Temperatura en la habitaciÃ³n.
    - **Humidity**: Humedad en la habitaciÃ³n.
    - **Light**: Nivel de luz en la habitaciÃ³n.
    - **CO2**: Nivel de diÃ³xido de carbono en la habitaciÃ³n.
    - **HumidityRatio**: RelaciÃ³n de humedad en la habitaciÃ³n.
    - **Occupancy**: Variable objetivo que indica si la habitaciÃ³n estÃ¡ ocupada (1) o no (0).
     """)

    # Cargar el modelo
    def load_model():
        try:
            with gzip.open('random_forest_model.pkl.gz', 'rb') as f:
                model = pickle.load(f)
            return model
        except Exception as e:
            st.error(f"Error al cargar el modelo: {e}")
            return None

    # Verificar si el modelo estÃ¡ cargado en la sesiÃ³n
    if "model" not in st.session_state:
        st.session_state.model = load_model()

    if st.session_state.model is not None:
        st.success("Modelo cargado correctamente.")
        model = st.session_state.model

        # **Solo aparece en la secciÃ³n Random Forest**
        st.markdown("### Hacer una predicciÃ³n")
        st.write("Introduce valores para hacer una predicciÃ³n:")
        inputs = {}

        # Diccionario con valores mÃ­nimos y mÃ¡ximos de cada variable
        min_max_dict = {
            'Temperature': (19.0, 25.0),
            'Humidity': (20.0, 60.0),
            'Light': (0.0, 1500.0),
            'CO2': (400.0, 1200.0),
            'HumidityRatio': (0.003, 0.007)
        }

        columnas_modelo = list(min_max_dict.keys())

        for col in columnas_modelo:
            min_val, max_val = min_max_dict[col]
            min_val, max_val = float(min_val), float(max_val)
            inputs[col] = st.number_input(
                f"{col} ({min_val} - {max_val})", 
                min_value=min_val, 
                max_value=max_val, 
                value=(min_val + max_val) / 2
            )

        if st.button("Predecir"):
            input_df = pd.DataFrame([inputs])
            prediccion = model.predict(input_df)
            ocupacion = "Ocupada" if prediccion[0] == 1 else "No Ocupada"
            st.success(f"La predicciÃ³n de ocupaciÃ³n es: {ocupacion}")

            # Importancia de las variables
            st.markdown("### Importancia de las variables")
            importancia = model.feature_importances_
            imp_df = pd.DataFrame({'Variable': columnas_modelo, 'Importancia': importancia})
            imp_df = imp_df.sort_values(by='Importancia', ascending=False)

            plt.figure(figsize=(8, 5))
            sns.barplot(x='Importancia', y='Variable', data=imp_df, palette='viridis')
            st.pyplot(plt)

    else:
        st.error("No se pudo cargar el modelo. Verifica el archivo.")

    st.sidebar.info("Esta aplicaciÃ³n predice la ocupaciÃ³n de una habitaciÃ³n usando un modelo Random Forest.")

# ==============================
# SECCIÃ“N: REDES NEURONALES
# ==============================
if seccion == "Modelo de redes neuronales":
    # --- Cargar modelo y scaler ---
    @st.cache_resource
    def load_assets():
        model = tf.keras.models.load_model("best_model.h5")
        with open("scaler.pkl", "rb") as f:
            scaler = pickle.load(f)
        return model, scaler

    model, scaler = load_assets()

    # --- TÃ­tulo de la aplicaciÃ³n ---
    st.title("ğŸ” PredicciÃ³n de OcupaciÃ³n con Redes Neuronales")

    st.markdown("Ingrese los valores de las variables para hacer una predicciÃ³n:")

    # --- Entrada de usuario con sliders ---
    temperature = st.slider("Temperature (Â°C)", 19.0, 25.0, 22.0)
    humidity = st.slider("Humidity (%)", 20.0, 60.0, 40.0)
    light = st.slider("Light (lux)", 0.0, 1500.0, 750.0)
    co2 = st.slider("CO2 (ppm)", 400.0, 1200.0, 800.0)
    humidity_ratio = st.slider("Humidity Ratio", 0.003, 0.007, 0.005)

    # --- Inicializar historial de predicciones ---
    if "history" not in st.session_state:
        st.session_state.history = []

    # --- SecciÃ³n de Redes Neuronales ---
    st.subheader("ğŸ¤– PredicciÃ³n con Redes Neuronales")

    # --- BotÃ³n de predicciÃ³n ---
    if st.button("Predecir con Redes Neuronales"):
        # Crear array con los valores ingresados
        input_data = np.array([[temperature, humidity, light, co2, humidity_ratio]])
        
        # Escalar los valores de entrada
        input_scaled = scaler.transform(input_data)
        
        # Hacer la predicciÃ³n con el modelo
        prediction = model.predict(input_scaled)

        # Verificar si la predicciÃ³n tiene la forma esperada
        if prediction.ndim == 2 and prediction.shape[1] > 1:
            predicted_class = np.argmax(prediction)  # Softmax
        else:
            predicted_class = int(round(prediction[0]))  # Salida escalar
        
        # Guardar en el historial solo para la secciÃ³n de redes neuronales
        st.session_state.history.append({
            "Temperature": temperature,
            "Humidity": humidity,
            "Light": light,
            "CO2": co2,
            "Humidity Ratio": humidity_ratio,
            "Prediction": "Ocupada" if predicted_class == 1 else "Desocupada"
        })
        
        # Mostrar el resultado
        st.subheader("ğŸ§  Resultado de la PredicciÃ³n:")
        if predicted_class == 1:
            st.success("âœ… La sala estÃ¡ ocupada.")
        else:
            st.warning("âŒ La sala estÃ¡ desocupada.")

        # Mostrar probabilidades de salida
        st.write("ğŸ“Š **PredicciÃ³n cruda (probabilidades softmax):**", prediction)

# --- Mostrar hiperparÃ¡metros del modelo ---
    st.subheader("ğŸ“Œ HiperparÃ¡metros del Modelo")
    st.write({
        "Capas Ocultas": 1,
        "Neuronas en capa oculta": 176,
        "FunciÃ³n de ActivaciÃ³n": "ReLU",
        "Optimizador": "RMSprop",
        "Learning Rate": 0.065,
        "Batch Size": 24,
        "Epochs": 5
    })



